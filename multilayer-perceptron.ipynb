{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NeuronLayer():\n",
    "    def __init__(self, number_of_neurons, inputs_per_neuron):\n",
    "        self.synaptic_weights = 2 * np.random.random((inputs_per_neuron, number_of_neurons)) -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork():\n",
    "    def __init__(self, layer1, layer2):\n",
    "        self.layer1 = layer1 \n",
    "        self.layer2 = layer2\n",
    "        \n",
    "    def __sigmoid(self, x):\n",
    "        return 1/(1 + np.exp(-x))\n",
    "    \n",
    "    def __sigmoid_derivative(self, x):\n",
    "        return x * (1 - x)\n",
    "    \n",
    "    def train(self, training_set_input, training_set_output, number_iterations):\n",
    "        # back propagation and updating the weights\n",
    "        for i in range(number_iterations):\n",
    "            # pass training set through network \n",
    "            layer1_output, layer2_output = self.think(training_set_input)\n",
    "            \n",
    "            # calculate the error for layer 2\n",
    "            layer2_error = training_set_output - layer2_output\n",
    "            layer2_delta = layer2_error * self.__sigmoid_derivative(layer2_output)\n",
    "            \n",
    "            # calculate the error for layer 1 \n",
    "            layer1_error = layer2_delta.dot(self.layer2.synaptic_weights.T)\n",
    "            layer1_delta = layer1_error * self.__sigmoid_derivative(layer1_output)\n",
    "            \n",
    "            # updat the weights \n",
    "            layer1_adjustment = training_set_inputs.T.dot(layer1_delta)\n",
    "            layer2_adjustment = layer1_output.T.dot(layer2_delta)\n",
    "            \n",
    "            # adjust the weights \n",
    "            self.layer1.synaptic_weights += layer1_adjustment \n",
    "            self.layer2.synaptic_weights += layer2_adjustment \n",
    "            \n",
    "    def think(self, inputs):\n",
    "        # forward propagate \n",
    "        layer1_output = self.__sigmoid(np.dot(inputs, self.layer1.synaptic_weights))\n",
    "        layer2_output = self.__sigmoid(np.dot(layer1_output, self.layer2.synaptic_weights))\n",
    "        return layer1_output, layer2_output\n",
    "    \n",
    "    def print_weights(self):\n",
    "        print(\"Layer 1(4 neurons, 3 inputs each): \")\n",
    "        print(self.layer1.synaptic_weights)\n",
    "        print(\"Layer 2(1 neuron with 4 inputs)\")\n",
    "        print(self.layer2.synaptic_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1(4 neurons, 3 inputs each): \n",
      "[[-0.16595599  0.44064899 -0.99977125 -0.39533485]\n",
      " [-0.70648822 -0.81532281 -0.62747958 -0.30887855]\n",
      " [-0.20646505  0.07763347 -0.16161097  0.370439  ]]\n",
      "Layer 2(1 neuron with 4 inputs)\n",
      "[[-0.5910955 ]\n",
      " [ 0.75623487]\n",
      " [-0.94522481]\n",
      " [ 0.34093502]]\n",
      "Layer 1(4 neurons, 3 inputs each): \n",
      "[[ 0.32433248  4.66285083 -6.22969441 -8.89984383]\n",
      " [ 0.20298513 -8.89373934 -6.23848225  4.49844839]\n",
      " [-0.03194164 -0.59786084  0.05056137 -0.42117751]]\n",
      "Layer 2(1 neuron with 4 inputs)\n",
      "[[ -8.54366996]\n",
      " [ 10.61999447]\n",
      " [-22.46294382]\n",
      " [ 10.37534933]]\n",
      "[ 0.00609014]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # seed the random number generator \n",
    "    np.random.seed(1)\n",
    "    \n",
    "    # create layers\n",
    "    layer1 = NeuronLayer(4, 3)\n",
    "    layer2 = NeuronLayer(1, 4)\n",
    "    \n",
    "    # create neural network \n",
    "    neural_network = NeuralNetwork(layer1, layer2)\n",
    "    \n",
    "    # print initial weights \n",
    "    neural_network.print_weights()\n",
    "    \n",
    "    # training set data \n",
    "    training_set_inputs = np.array([[0, 0, 1], [0, 1, 1], [1, 0, 1], [0, 1, 0], [1, 0, 0], [1, 1, 1], [0, 0, 0]])\n",
    "    training_set_outputs = np.array([[0, 1, 1, 1, 1, 0, 0]]).T\n",
    "    \n",
    "    # run the iterations \n",
    "    neural_network.train(training_set_inputs, training_set_outputs, 100000)\n",
    "    \n",
    "    # print updated weights \n",
    "    neural_network.print_weights()\n",
    "    \n",
    "    # testing data \n",
    "    training_data = np.array([1,1,0])\n",
    "    hidden_state, output = neural_network.think(training_data)\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
