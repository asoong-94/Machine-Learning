{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NeuronLayer():\n",
    "    def __init__(self, number_of_neurons, inputs_per_neuron):\n",
    "        self.synaptic_weights = 2 * np.random.random((inputs_per_neuron, number_of_neurons)) -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork():\n",
    "    def __init__(self, layer1, layer2):\n",
    "        self.layer1 = layer1 \n",
    "        self.layer2 = layer2\n",
    "        \n",
    "    def __sigmoid(self, x):\n",
    "        return 1/(1 + exp(-x))\n",
    "    \n",
    "    def __sigmoid_derivative(self, x):\n",
    "        return x * (1 - x)\n",
    "    \n",
    "    def train(self, training_set_input, training_set_output, number_iterations):\n",
    "        # back propagation and updating the weights\n",
    "        for i in range(number_iterations):\n",
    "            # pass training set through network \n",
    "            layer1_output, layer2_output = self.think(training_set_input)\n",
    "            \n",
    "            # calculate the error for layer 2\n",
    "            layer2_error = training_set_output - layer2_output\n",
    "            layer2_delta = layer2_error * self.__sigmoid_derivative(layer2_output)\n",
    "            \n",
    "            # calculate the error for layer 1 \n",
    "            layer1_error = layer2_detla.np.dot(self.layer2.synaptic_weights.T)\n",
    "            layer1_delta = layer1_error * self.__sigmoid_derivative(layer1_output)\n",
    "            \n",
    "            # updat the weights \n",
    "            layer1_adjustment = training_set_inputs.T.dot(layer1_delta)\n",
    "            layer2_adjustment = layer1_output.T.dot(layer2_delta)\n",
    "            \n",
    "            # adjust the weights \n",
    "            self.layer1.synaptic_weights += layer1_adjustment \n",
    "            self.layer2.synaptic_weights += layer2_adjustment \n",
    "            \n",
    "    def think(self, inputs):\n",
    "        # forward propagate \n",
    "        layer1_output = self.__sigmoid(np.dot(inputs, self.layer1.synaptic_weights))\n",
    "        layer2_output = self.__sigmoid(np.dot(layer1_output, self.layer2.synaptic_weights))\n",
    "        return layer1_output, layer2_output\n",
    "    \n",
    "    def print_weights(self):\n",
    "        print(\"Layer 1(4 neurons, 3 inputs each): \")\n",
    "        print(self.layer1.synaptic_weights)\n",
    "        print(\"Layer 2(1 neuron with 4 inputs)\")\n",
    "        print(self.layer2.synaptic_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1(4 neurons, 3 inputs each): \n",
      "[[-0.16595599  0.44064899 -0.99977125 -0.39533485]\n",
      " [-0.70648822 -0.81532281 -0.62747958 -0.30887855]\n",
      " [-0.20646505  0.07763347 -0.16161097  0.370439  ]]\n",
      "Layer 2(1 neuron with 4 inputs)\n",
      "[[-0.5910955 ]\n",
      " [ 0.75623487]\n",
      " [-0.94522481]\n",
      " [ 0.34093502]]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can't multiply sequence by non-int of type 'builtin_function_or_method'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-8c52c3a61155>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# run the iterations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mneural_network\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_set_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_set_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m# print updated weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-9d87d9dafb3a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, training_set_input, training_set_output, number_iterations)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber_iterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0;31m# pass training set through network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mlayer1_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer2_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_set_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;31m# calculate the error for layer 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-9d87d9dafb3a>\u001b[0m in \u001b[0;36mthink\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mthink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;31m# forward propagate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mlayer1_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__sigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msynaptic_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0mlayer2_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__sigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer1_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msynaptic_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlayer1_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer2_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: can't multiply sequence by non-int of type 'builtin_function_or_method'"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # seed the random number generator \n",
    "    np.random.seed(1)\n",
    "    \n",
    "    # create layers\n",
    "    layer1 = NeuronLayer(4, 3)\n",
    "    layer2 = NeuronLayer(1, 4)\n",
    "    \n",
    "    # create neural network \n",
    "    neural_network = NeuralNetwork(layer1, layer2)\n",
    "    \n",
    "    # print initial weights \n",
    "    neural_network.print_weights()\n",
    "    \n",
    "    # training set data \n",
    "    training_set_inputs = np.array([[0, 0, 1], [0, 1, 1], [1, 0, 1], [0, 1, 0], [1, 0, 0], [1, 1, 1], [0, 0, 0]])\n",
    "    training_set_outputs = np.array([[0, 1, 1, 1, 1, 0, 0]]).T\n",
    "    \n",
    "    # run the iterations \n",
    "    neural_network.train(training_set_inputs, training_set_outputs, 100000)\n",
    "    \n",
    "    # print updated weights \n",
    "    neural_network.print_weights()\n",
    "    \n",
    "    # testing data \n",
    "    training_data = np.array([1,1,0])\n",
    "    hidden_state, output = neural_network.think(training_data)\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
